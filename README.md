# ğŸŒ linguAI â€” Realâ€‘time STT â†”ï¸ Translation â†”ï¸ TTS (Linux)

> **English + PortuguÃªs** â€” One workstation. Realâ€‘time captions + translated voice for Google Meet/Zoom/Teams.
> Uses **Deepgram** (ASR), **Ollama** (local LLM translation), **ElevenLabs** (TTS) and **pythonâ€‘soundcard** loopback.

---

## ğŸ‡ºğŸ‡¸ Overview (English)

**What it does**

* Captures the **meeting audio** (system output) via loopback and **transcribes** it with **Deepgram**.
* Sends the text to **Ollama** for **translation** (e.g., EN â†’ PTâ€‘BR) and prints the result live.
* In the other direction, it takes **your microphone (PTâ€‘BR)** â†’ **Deepgram** â†’ **Ollama (PTâ†’EN)** â†’ **ElevenLabs TTS** and **plays** a natural English voice to a **virtual mic**, so participants hear you **in their language** with low latency.

**Why itâ€™s useful**

* Works across Google Meet/Zoom/Teams without plugins.
* Roundâ€‘trip from ASR â†’ LLM â†’ TTS under a few hundred ms per sentence chunk when tuned.
* Designed for real meetings: stable loopback routing, buffering to avoid halfâ€‘sentences, and explicit â€œtranslationâ€‘onlyâ€ prompts to prevent echoing.

---

## ğŸ‡§ğŸ‡· VisÃ£o Geral (PortuguÃªs)

**O que ele faz**

* Captura o **Ã¡udio da reuniÃ£o** (saÃ­da do sistema) via loopback e **transcreve** com **Deepgram**.
* Envia o texto para o **Ollama** para **traduÃ§Ã£o** (ex.: EN â†’ PTâ€‘BR) e mostra o resultado ao vivo.
* No sentido contrÃ¡rio, pega **seu microfone (PTâ€‘BR)** â†’ **Deepgram** â†’ **Ollama (PTâ†’EN)** â†’ **ElevenLabs TTS** e **toca** uma voz em inglÃªs em um **microfone virtual**, para que a outra pessoa te ouÃ§a **no idioma dela** com baixa latÃªncia.

**Por que Ã© Ãºtil**

* Funciona em Google Meet/Zoom/Teams sem plugins.
* LatÃªncia baixa por trecho (ASR â†’ LLM â†’ TTS), adequada para conversa.
* Pensado para reuniÃµes reais: roteamento estÃ¡vel, buffer de frases, prompt â€œapenas traduÃ§Ã£oâ€.

---

## âœ¨ Features

* ğŸ§ **Loopback robusto** com `python-soundcard` (PipeWire/PulseAudio).
* ğŸ—£ï¸ **ASR**: Deepgram **live** (`nova-3` por padrÃ£o).
* ğŸ” **TraduÃ§Ã£o local**: **Ollama** com modelo `zongwei/gemma3-translator:1b` (personalizÃ¡vel).
* ğŸ”Š **TTS**: **ElevenLabs** com voz clonada/personalizada.
* ğŸ§  **Buffer de frases**: agrega parciais e sÃ³ envia ao LLM quando a sentenÃ§a estÃ¡ â€œfechadaâ€ (ou por timeout), reduzindo erros.
* ğŸ” **SeguranÃ§a**: chaves via variÃ¡veis de ambiente (nÃ£o commitar secrets).

---

## ğŸ§± Architecture / Fluxo

```
[Meeting Audio (system out)] --loopback--> [Deepgram STT EN]
    -> [Buffer sentence] -> [Ollama ENâ†’PT] -> [Print PT captions]

[Your Mic (PT)] -> [Deepgram STT PT] -> [Ollama PTâ†’EN] -> [ElevenLabs TTS EN]
    -> [Virtual Mic / Default Output] -> Remote hears you in English
```

---

## ğŸ§© Requirements / Requisitos

* **Ubuntu** + **PipeWire/PulseAudio**
* **Python 3.10+**
* `pip install`: `soundcard`, `numpy`, `requests`, `deepgram-sdk`, `elevenlabs`, (opcional: `sounddevice`)
* **Ollama** rodando local
* **Deepgram API key**
* **ElevenLabs API key** (para TTS)
* `pavucontrol` (Ãºtil p/ roteamento)

> **Importante**: **NÃƒO** deixe chaves no cÃ³digo. Use variÃ¡veis de ambiente e **revogue** quaisquer chaves que jÃ¡ tenham sido expostas.

---

## ğŸ› ï¸ Setup

### 1) Instale dependÃªncias

```bash
sudo apt install pavucontrol
pip install soundcard numpy requests deepgram-sdk elevenlabs
```

### 2) Inicie o Ollama e baixe o modelo

```bash
ollama pull zongwei/gemma3-translator:1b
# ollama serve (se nÃ£o iniciar automaticamente)
```

### 3) Exporte as chaves (nÃ£o commit!)

```bash
export DEEPGRAM_API_KEY="coloque_sua_chave"
export ELEVEN_API_KEY="coloque_sua_chave"
export OLLAMA_URL="http://localhost:11434/api"    # use /chat ou /generate conforme funÃ§Ã£o
export OLLAMA_MODEL="zongwei/gemma3-translator:1b"
```

### 4) (Recomendado) Sink virtual estÃ¡vel para Bluetooth

Bluetooth (A2DP) **nÃ£o tem** loopback real. Crie um **sink virtual** e duplique para o headset:

```bash
pactl load-module module-null-sink sink_name=transcribe sink_properties=device.description=TranscribeSink
# descubra seu sink bluetooth
pactl list short sinks | grep -i bluez
# duplique TranscribeSink para o sink BT
pactl load-module module-loopback source=transcribe.monitor sink=<SEU_SINK_BLUETOOTH> latency_msec=5
```

No **pavucontrol â†’ ReproduÃ§Ã£o**, direcione o navegador/player para **TranscribeSink**.
O script vai capturar de **TranscribeSink.monitor** (nÃ­vel garantido) e vocÃª continua ouvindo no fone BT.

---

## â–¶ï¸ How to Run / Como usar

### A) **Captions ENâ†’PT** (captura do Ã¡udio da reuniÃ£o)

Arquivo: `playback_transcribe.py` (o que vocÃª colou)

1. Garanta que o app de reuniÃ£o (ou navegador) estÃ¡ enviando Ã¡udio para **TranscribeSink** (ou para a saÃ­da que possua **monitor** real).
2. Rode:

   ```bash
   export LANGUAGE="en-US"            # idioma do que vocÃª ouve
   export DG_MODEL="nova-3"
   export SAMPLE_RATE=48000
   python playback_transcribe.py
   ```
3. Em **pavucontrol â†’ Gravando**, o processo deve estar em **Monitor of TranscribeSink** (ou â€œBuilt-in Audio â€¦ monitorâ€).
4. As traduÃ§Ãµes **PTâ€‘BR** aparecem no terminal.

> **Dica**: no seu cÃ³digo, evite `loopbacks[2]`. FaÃ§a seleÃ§Ã£o por nome/id do monitor (ex: â€œtranscribeâ€/â€œbuilt-inâ€) para nÃ£o depender de Ã­ndices variÃ¡veis.

### B) **Speak PTâ†’EN (voz)** com TTS

**Mic PT to  EN TTS**)

1. Configure:

   ```bash
   export ELEVEN_API_KEY="..."   # sua chave
   export EL_VOICE_ID="..."      # id da sua voz
   export EL_TTS_MODEL="eleven_flash_v2_5"
   export SAMPLE_RATE=16000      # o script usa 16 kHz para TTS PCM; Deepgram aceita
   ```
2. Rode o script. Ele:

   * escuta **seu microfone** em PTâ€‘BR,
   * transcreve (Deepgram),
   * traduz **PTâ†’EN** (Ollama),
   * sintetiza voz **EN** (ElevenLabs) e toca no **backend pulse**.
3. Para mandar ao **microfone virtual** da videoconferÃªncia:

   * mantenha esse output roteado para o seu **VirtualMicSink**/**TranscribeSink**, ou
   * use ferramentas de loopback para que o app de reuniÃ£o receba o Ã¡udio do script como **input**.

---

## âš™ï¸ Tuning / Ajustes

* **Buffer de frases**
  Use `BUFFER_TIMEOUT` (ex.: `0.6â€“1.0s`) e `BUFFER_MAX_CHARS` (ex.: `160`) para reduzir cortes no meio da frase.
* **Evite eco** no Ollama
  Use **/api/chat** com `system: "Return ONLY the translation"` ou um prompt com â€œ### TRANSLATION:â€ e `temperature=0`.
* **48 kHz** no loopback
  `SAMPLE_RATE=48000` Ã© estÃ¡vel para PipeWire/PulseAudio endâ€‘toâ€‘end.
* **Gate de silÃªncio**
  Descarte blocos com RMS muito baixo para nÃ£o enviar vazios.

---

## ğŸ§ª Quick sanity checks

* **Ollama up**:

  ```bash
  curl -s http://localhost:11434/api/generate \
    -d '{"model":"zongwei/gemma3-translator:1b","prompt":"Translate to Portuguese: Hello world","stream":false}'
  ```
* **Monitor com nÃ­vel**: em **pavucontrol â†’ Gravando**, a barra do seu processo **precisa** oscilar.
  Se ficar zerada, direcione o player para **TranscribeSink** ou troque a origem do processo para **Monitor of Builtâ€‘in/TranscribeSink**.

---

## ğŸ› Troubleshooting

* **SÃ³ aparece â€œTranslate this sentence to Portuguese: â€¦â€ no terminal**
  O modelo ecoou a instruÃ§Ã£o ou houve erro e vocÃª imprimiu o *prompt/texto* em vez da resposta.
  â†’ Use `/api/chat` com â€œONLY the translationâ€ **ou** o prompt â€œ### TRANSLATION:â€. Logue `r.status_code` e `r.text`.
* **Bluetooth sem Ã¡udio no monitor**
  Normal: A2DP nÃ£o expÃµe monitor real. Use **TranscribeSink** + loopback para o sink BT.
* **Nada imprime em flush por pontuaÃ§Ã£o**
  Lembre de dar `print(out, flush=True)` tambÃ©m no ramo que encerra por `.`/`!`/`?`.

---

## ğŸ” Security

* **NUNCA** commite chaves (`DEEPGRAM_API_KEY`, `ELEVEN_API_KEY`).
* Revogue as que jÃ¡ foram expostas em snippets antigos.

---

## ğŸ—ºï¸ Roadmap

* ğŸ”“ **Port 100% openâ€‘source** (ASR + TTS locais) para latÃªncia ~**<50 ms** por trecho curto.
* ğŸ›ï¸ Autoâ€‘detecÃ§Ã£o de monitor ativo por RMS.
* ğŸ§ª Testes automatizados de Ã¡udio (latÃªncia e dropouts).

---

## ğŸ“„ Example env (copy/paste)

```bash
# Common
export OLLAMA_URL="http://localhost:11434/api"
export OLLAMA_MODEL="zongwei/gemma3-translator:1b"

# Captions EN->PT (playback_transcribe.py)
export DEEPGRAM_API_KEY="..."
export LANGUAGE="en-US"
export DG_MODEL="nova-3"
export SAMPLE_RATE=48000
export BUFFER_TIMEOUT=0.8
export BUFFER_MAX_CHARS=160

# Mic PT->EN + TTS
export ELEVEN_API_KEY="..."
export EL_VOICE_ID="HDNjMGNzhjXlh3sYMYQI" #ipssbruno real voice
export EL_TTS_MODEL="eleven_flash_v2_5"
```

---

## ğŸ§­ Notes from your code (applied)

* Usa `python-soundcard` para pegar **loopback** (evita a dependÃªncia do â€œmonitorâ€ do PortAudio).
* Faz **downmix** para **mono PCM16** antes de enviar Ã  Deepgram.
* **Agrega** parciais em `printer_worker` para evitar traduÃ§Ã£o de **meias frases**.
* Para estabilidade com Bluetooth, preferir **TranscribeSink.monitor** (nÃ£o indexar por `[2]`).


